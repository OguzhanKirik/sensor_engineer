# Sensor Fusion 

This repository summarizes the lessons and projects from a Sensor Fusion curriculum focused on combining camera and lidar data for perception tasks in autonomous systems. The course includes feature tracking, collision detection, sensor integration, and 3D object tracking techniques.

---

## Overview

---

### **L1: Engineering a Collision Detection System**
Understand:
- Collision detection concepts  
- Time-to-Collision (TTC) estimation  
- Using **lidar** and **camera** data to compute TTC  

---

### **L2: Tracking Image Features**
Explore:
- Image gradients and filtering  
- Corner detection (e.g., Harris, Shi-Tomasi)  
- Feature extraction and matching  
- Tracking features across multiple frames  

---

### **L3 Project: Camera-Based 2D Feature Tracking**
Implement a full 2D feature-tracking pipeline using OpenCV to extract, match, and track keypoints between images.

---

### **L4: Combining Camera and Lidar**
Learn how to fuse camera and lidar data:
- Project lidar points into the image  
- Associate features across multiple sensors  
- Improve tracking robustness and accuracy using multi-sensor data  

---

### **L5 Project: Track an Object in 3D Space**
Build a system that:
- Fuses camera and lidar detections  
- Tracks objects through time  
- Estimates 3D motion, velocity, and TTC using multi-sensor data  

---



